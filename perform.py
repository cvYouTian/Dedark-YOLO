from typing import Union, List, Optional, Tuple
from tqdm import tqdm
import json
from datetime import datetime
import shutil
import sys
import os
import torch
from pathlib import Path
from typing import Union
import cv2
import netron
import time
from ultralytics import YOLO

os.environ["WANDB_MODE"] = "offline"  # ç¦»çº¿æ¨¡å¼


def train():
    # Load a model
    model = YOLO('yolov8n.yaml')
    # model = RTDETR('rtdetr-l.yaml')
    # print(model)
    # model = YOLO('yolov8m.pt')

    # åšé¢„è®­ç»ƒ
    # model = YOLO('yolov8x.pt')
    # model = YOLO('yolov8n.yaml').load('yolov8n.pt')

    # Train the model
    # model.train(data="HSTS6.yaml", epochs=150, imgsz=640)
    model.train(data="coco128.yaml", epochs=5, imgsz=640)


def train_lowght():
    # Load a model
    model = YOLO('yolov8l.yaml')
    model.train(data="tielu.yaml", epochs=5, imgsz=640)


def onnx(path: Union[str, Path] = "/home/youtian/Documents/pro/pyCode/Dedark-YOLO/epoch20.pt"):
    # you need numpy==1.24.3 ,otherwise it will report Error
    onnxpath = Path(path).with_suffix(".onnx")
    print(onnxpath)
    if not onnxpath.exists():
        model = YOLO(path)
        # Export the model
        model.export(format='onnx')
    try:
        netron.start(str(onnxpath))
    except Exception as e:
        print(e)


def test_img():
    model = YOLO("/home/youtian/Documents/pro/pyCode/Dedark-YOLO/runs/detect/6-1-1833/no-re_loss.pt")
    img = cv2.imread(
        "/home/youtian/Documents/pro/pyCode/datasets/darkpic_test/192.168.39.20_20240727_060304_2246886_2.jpg")
    # img = cv2.imread("/home/youtian/Documents/pro/pyCode/datasets/tielu-yolo/images/test/192.168.39.20_20240727_060304_2246886_2.jpg")
    res = model(img)
    ann = res[0].plot()
    while True:
        cv2.imshow("yolo", ann)
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break
    cur_path = sys.path[0]
    print(cur_path, sys.path)

    cv2.imwrite(cur_path + os.sep + "out2.jpg", ann)


def test_video():
    model = YOLO("/home/youtian/Documents/pro/pyCode/easy_YOLOv8/yolov8x.pt")
    path = Path("/home/youtian/Documents/pro/pyCode/datasets/shitang.mp4")
    cap = cv2.VideoCapture(str(path))

    if not cap.isOpened():
        print("Error: Could not open video.")
        exit()

    size = (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)))

    # ä½¿ç”¨æ­£ç¡®çš„æ–‡ä»¶å
    output_path = Path(f"{path.stem}_output.mp4")
    fourcc = cv2.VideoWriter_fourcc(*'XVID')  # å°è¯•ä½¿ç”¨XVIDç¼–ç 
    out = cv2.VideoWriter(str(output_path), fourcc, 40, size)

    while cap.isOpened():
        ret, frame = cap.read()
        if ret:
            res = model(frame)
            ann = res[0].plot(line_width=3)
            cv2.imshow("yolo", ann)
            out.write(ann)
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break
        else:
            break

    cv2.destroyAllWindows()
    cap.release()
    out.release()




def test_folders(
        model_path: Union[
            str, Path] = "/home/youtian/best.pt",
        srcpath: Union[str, Path] = "/home/youtian/val",
        method: str = "YOLO",
        output_size: Tuple[int, int] = (1080, 720),
        confidence_threshold: float = 0.25,
        save_txt: bool = False,
        save_json: bool = True,
        supported_formats: List[str] = None
) -> dict:
    """
    ä¼˜åŒ–çš„æ‰¹é‡å›¾ç‰‡æ£€æµ‹å‡½æ•°

    Args:
        model_path: æ¨¡å‹æƒé‡æ–‡ä»¶è·¯å¾„
        srcpath: æºå›¾ç‰‡æ–‡ä»¶å¤¹è·¯å¾„
        method: æ£€æµ‹æ–¹æ³• ("YOLO" æˆ– "RTDETR")
        output_size: è¾“å‡ºå›¾ç‰‡å°ºå¯¸ (width, height)
        confidence_threshold: ç½®ä¿¡åº¦é˜ˆå€¼
        save_txt: æ˜¯å¦ä¿å­˜txtæ ¼å¼çš„æ£€æµ‹ç»“æœ
        save_json: æ˜¯å¦ä¿å­˜jsonæ ¼å¼çš„æ£€æµ‹ç»“æœ
        supported_formats: æ”¯æŒçš„å›¾ç‰‡æ ¼å¼åˆ—è¡¨

    Returns:
        dict: åŒ…å«æ£€æµ‹ç»Ÿè®¡ä¿¡æ¯çš„å­—å…¸
    """

    # é»˜è®¤æ”¯æŒçš„å›¾ç‰‡æ ¼å¼
    if supported_formats is None:
        supported_formats = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp']

    # è·¯å¾„å¤„ç†
    model_path = Path(model_path)
    src_path = Path(srcpath)

    # éªŒè¯è·¯å¾„
    if not model_path.exists():
        raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
    if not src_path.exists():
        raise FileNotFoundError(f"æºæ–‡ä»¶å¤¹ä¸å­˜åœ¨: {src_path}")

    # åŠ è½½æ¨¡å‹
    print(f"æ­£åœ¨åŠ è½½æ¨¡å‹: {model_path}")
    try:
        if method.lower() == "rtdetr":
            # model = RTDETR(str(model_path))  # å¦‚æœéœ€è¦æ”¯æŒRTDETR
            raise NotImplementedError("RTDETR support not implemented yet")
        else:
            model = YOLO(model_path)
            model.conf = confidence_threshold  # è®¾ç½®ç½®ä¿¡åº¦é˜ˆå€¼
    except Exception as e:
        raise RuntimeError(f"æ¨¡å‹åŠ è½½å¤±è´¥: {e}")

    # åˆ›å»ºè¾“å‡ºæ–‡ä»¶å¤¹
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    model_name = model_path.parts[-3] if len(model_path.parts) >= 3 else model_path.stem
    dst_folder = Path(sys.path[0]) / f"{model_name}_test_results_{timestamp}"

    # æ¸…ç†å¹¶åˆ›å»ºè¾“å‡ºæ–‡ä»¶å¤¹
    if dst_folder.exists():
        shutil.rmtree(dst_folder)
    dst_folder.mkdir(parents=True)

    # åˆ›å»ºå­æ–‡ä»¶å¤¹
    images_folder = dst_folder / "images"
    images_folder.mkdir()

    if save_txt:
        labels_folder = dst_folder / "labels"
        labels_folder.mkdir()

    # è·å–æ‰€æœ‰å›¾ç‰‡æ–‡ä»¶
    image_files = []
    for fmt in supported_formats:
        image_files.extend(src_path.glob(f"*{fmt}"))
        image_files.extend(src_path.glob(f"*{fmt.upper()}"))

    if not image_files:
        raise ValueError(f"åœ¨ {src_path} ä¸­æœªæ‰¾åˆ°æ”¯æŒçš„å›¾ç‰‡æ–‡ä»¶")

    print(f"æ‰¾åˆ° {len(image_files)} å¼ å›¾ç‰‡")

    # åˆå§‹åŒ–ç»Ÿè®¡å˜é‡
    total_time = 0
    successful_detections = 0
    failed_detections = 0
    detection_results = []

    # æ‰¹é‡å¤„ç†å›¾ç‰‡
    with tqdm(image_files, desc="å¤„ç†å›¾ç‰‡", unit="å¼ ") as pbar:
        for img_path in pbar:
            try:
                # è®°å½•å¼€å§‹æ—¶é—´
                start_time = time.time()

                # è¯»å–å›¾ç‰‡
                img = cv2.imread(str(img_path))
                if img is None:
                    print(f"è­¦å‘Š: æ— æ³•è¯»å–å›¾ç‰‡ {img_path}")
                    failed_detections += 1
                    continue

                # è¿›è¡Œæ¨ç†
                results = model(img, verbose=False)  # verbose=False å‡å°‘è¾“å‡º

                # è®°å½•ç»“æŸæ—¶é—´
                end_time = time.time()
                inference_time = end_time - start_time
                total_time += inference_time

                # å¤„ç†æ£€æµ‹ç»“æœ
                result = results[0]
                annotated_img = result.plot()

                # è°ƒæ•´å›¾ç‰‡å°ºå¯¸
                resized_img = cv2.resize(annotated_img, output_size)

                # ä¿å­˜æ ‡æ³¨å›¾ç‰‡
                output_img_path = images_folder / img_path.name
                cv2.imwrite(str(output_img_path), resized_img)

                # ä¿å­˜æ£€æµ‹ç»“æœ (txtæ ¼å¼)
                if save_txt and hasattr(result, 'boxes') and result.boxes is not None:
                    txt_path = labels_folder / f"{img_path.stem}.txt"
                    save_detection_txt(result, txt_path, img.shape)

                # æ”¶é›†ç»Ÿè®¡ä¿¡æ¯
                detection_info = {
                    'filename': img_path.name,
                    'inference_time': inference_time,
                    'detection_count': len(result.boxes) if result.boxes is not None else 0,
                    'image_size': img.shape[:2],
                    'confidences': result.boxes.conf.tolist() if result.boxes is not None else []
                }
                detection_results.append(detection_info)

                successful_detections += 1

                # æ›´æ–°è¿›åº¦æ¡ä¿¡æ¯
                avg_time = total_time / successful_detections if successful_detections > 0 else 0
                pbar.set_postfix({
                    'avg_time': f"{avg_time:.3f}s",
                    'detections': len(result.boxes) if result.boxes is not None else 0
                })

            except Exception as e:
                print(f"å¤„ç†å›¾ç‰‡ {img_path} æ—¶å‡ºé”™: {e}")
                failed_detections += 1
                continue

    # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
    avg_inference_time = total_time / successful_detections if successful_detections > 0 else 0
    total_detections = sum(info['detection_count'] for info in detection_results)

    # ç»Ÿè®¡ç»“æœ
    stats = {
        'model_path': str(model_path),
        'source_path': str(src_path),
        'output_path': str(dst_folder),
        'timestamp': timestamp,
        'total_images': len(image_files),
        'successful_detections': successful_detections,
        'failed_detections': failed_detections,
        'total_inference_time': total_time,
        'average_inference_time': avg_inference_time,
        'total_objects_detected': total_detections,
        'confidence_threshold': confidence_threshold,
        'output_size': output_size,
        'detection_details': detection_results
    }

    # ä¿å­˜ç»Ÿè®¡ç»“æœ
    if save_json:
        stats_path = dst_folder / "detection_stats.json"
        with open(stats_path, 'w', encoding='utf-8') as f:
            json.dump(stats, f, indent=2, ensure_ascii=False)

    # æ‰“å°ç»“æœæ‘˜è¦
    print_detection_summary(stats)

    return stats


def save_detection_txt(result, txt_path: Path, img_shape: tuple):
    """ä¿å­˜æ£€æµ‹ç»“æœåˆ°txtæ–‡ä»¶ (YOLOæ ¼å¼)"""
    try:
        with open(txt_path, 'w') as f:
            if result.boxes is not None:
                boxes = result.boxes
                for i in range(len(boxes)):
                    cls = int(boxes.cls[i])
                    conf = float(boxes.conf[i])
                    x, y, w, h = boxes.xywhn[i].tolist()  # å½’ä¸€åŒ–åæ ‡
                    f.write(f"{cls} {x:.6f} {y:.6f} {w:.6f} {h:.6f} {conf:.6f}\n")
    except Exception as e:
        print(f"ä¿å­˜txtæ–‡ä»¶å¤±è´¥ {txt_path}: {e}")


def print_detection_summary(stats: dict):
    """æ‰“å°æ£€æµ‹ç»“æœæ‘˜è¦"""
    print("\n" + "=" * 60)
    print("æ£€æµ‹ç»“æœæ‘˜è¦")
    print("=" * 60)
    print(f"ğŸ“ è¾“å‡ºæ–‡ä»¶å¤¹: {stats['output_path']}")
    print(f"ğŸ“Š å¤„ç†ç»Ÿè®¡:")
    print(f"   â€¢ æ€»å›¾ç‰‡æ•°: {stats['total_images']}")
    print(f"   â€¢ æˆåŠŸå¤„ç†: {stats['successful_detections']}")
    print(f"   â€¢ å¤„ç†å¤±è´¥: {stats['failed_detections']}")
    print(f"   â€¢ æˆåŠŸç‡: {stats['successful_detections'] / stats['total_images'] * 100:.1f}%")

    print(f"â±ï¸  æ€§èƒ½ç»Ÿè®¡:")
    print(f"   â€¢ æ€»æ¨ç†æ—¶é—´: {stats['total_inference_time']:.2f}s")
    print(f"   â€¢ å¹³å‡æ¨ç†æ—¶é—´: {stats['average_inference_time']:.3f}s")
    print(f"   â€¢ æ¨ç†é€Ÿåº¦: {1 / stats['average_inference_time']:.1f} FPS"
          if stats['average_inference_time'] > 0 else "   â€¢ æ¨ç†é€Ÿåº¦: N/A")

    print(f"ğŸ¯ æ£€æµ‹ç»Ÿè®¡:")
    print(f"   â€¢ æ€»æ£€æµ‹ç›®æ ‡æ•°: {stats['total_objects_detected']}")
    print(f"   â€¢ å¹³å‡æ¯å¼ å›¾ç‰‡ç›®æ ‡æ•°: {stats['total_objects_detected'] / stats['successful_detections']:.1f}"
          if stats['successful_detections'] > 0 else "   â€¢ å¹³å‡æ¯å¼ å›¾ç‰‡ç›®æ ‡æ•°: 0")

    # ç½®ä¿¡åº¦ç»Ÿè®¡
    if stats['detection_details']:
        all_confidences = []
        for detail in stats['detection_details']:
            all_confidences.extend(detail['confidences'])

        if all_confidences:
            print(f"ğŸ“ˆ ç½®ä¿¡åº¦ç»Ÿè®¡:")
            print(f"   â€¢ æœ€é«˜ç½®ä¿¡åº¦: {max(all_confidences):.3f}")
            print(f"   â€¢ æœ€ä½ç½®ä¿¡åº¦: {min(all_confidences):.3f}")
            print(f"   â€¢ å¹³å‡ç½®ä¿¡åº¦: {sum(all_confidences) / len(all_confidences):.3f}")

    print("=" * 60)



def Para4pt(model):
    # ä¸€å®šè¦æ‰¾åˆ°æƒé‡ä¸­çš„modelï¼Œæ‰å¯ä»¥åç»­è¿›è¡Œparameterçš„è®¡ç®—
    # YOLOv8
    # model = model["model"].model
    # YOLOv7
    model = model["model"].model

    total_params = sum(p.numel() for p in model.parameters())
    print(f'{total_params:,} total parameters.')
    # print(f'{total_params / (1024 * 1024):.2f}M total parameters.')


def FLOPs_Para4pt():
    from thop import profile
    """
    æ ¹æ®pytorchçš„ptæ–‡ä»¶æ¥è®¡ç®—æ¨¡å‹çš„FLOPså’Œå‚æ•°é‡ï¼Œuse thop
    Args:
        model:pytorchåŠ è½½å¥½çš„æ¨¡å‹æ–‡ä»¶
    Returns:None
    """

    device = "cuda" if torch.cuda.is_available() else "cpu"
    pa = Path("/home/youtian/Documents/pro/pyCode/ultralytics-YOLOv8/yolov8l.pt")
    model = torch.load(str(pa).strip())

    # å…ˆå°†æ¨¡å‹çš„è°ƒæ•´ä¸ºhalf()æ ¼å¼ï¼Œå†å°†å…¶è´´åˆ°GPU
    model = model.get("model").half().to(device)

    # å‡è®¾æ¨¡å‹æœŸæœ›çš„è¾“å…¥æ˜¯3ä¸ªé€šé“çš„å›¾åƒ
    input_tensor = torch.randn(1, 3, 640, 640)

    # åŒç†ï¼Œå°†æ•°æ®è½¬åŒ–æˆåŠç²¾åº¦ä¹‹åå†åŠ è½½åˆ°GPU
    input_tensor = input_tensor.half().to(device)

    # è°ƒç”¨profileå‡½æ•°è®¡ç®—FLOPså’Œå‚æ•°é‡
    macs, params = profile(model, inputs=(input_tensor,))

    # å°†macsè½¬åŒ–æˆflops
    flops = macs / 1E9 * 2
    params = params / 1E6

    print('flops:{}'.format(flops))
    print('params:{}'.format(params))


def calculate_detection_metrics(metrics, class_names=None):
    """
    è®¡ç®—æ£€å‡ºç‡å’Œæ¼æ£€ç‡æŒ‡æ ‡
    æ£€å‡ºç‡ï¼ˆDetection Rate, DRï¼‰= TP / (TP + FN) = 1 - æ¼æ£€ç‡
    æ¼æ£€ç‡ï¼ˆFalse Negative Rate, FNRï¼‰= FN / (FN + TP) = FN / Total_Ground_Truth

    Args:
        metrics: YOLO validation metrics
        class_names: ç±»åˆ«åç§°åˆ—è¡¨ï¼Œå¦‚ ['person', 'debrisflow', 'rockfall']

    Returns:
        dict: åŒ…å«æ€»ä½“å’Œå„ç±»åˆ«æ£€å‡ºç‡ã€æ¼æ£€ç‡çš„å­—å…¸
    """
    # è·å–æ··æ·†çŸ©é˜µ
    confusion_matrix = metrics.confusion_matrix

    if confusion_matrix is None:
        print("Warning: No confusion matrix available")
        return None

    # è·å–æ··æ·†çŸ©é˜µæ•°æ®
    matrix = confusion_matrix.matrix
    nc = confusion_matrix.nc  # ç±»åˆ«æ•°é‡

    # è®¡ç®—æ¯ä¸ªç±»åˆ«çš„TP, FN, DR, FNR
    tp_per_class = []
    fn_per_class = []
    dr_per_class = []  # Detection Rate
    fnr_per_class = []  # False Negative Rate

    for i in range(nc):
        # TP: å¯¹è§’çº¿å…ƒç´ 
        tp = matrix[i, i]
        # FN: è¯¥ç±»åˆ«åˆ—çš„æ€»å’Œå‡å»TP (çœŸå®æ ‡ç­¾ä¸ºè¯¥ç±»ä½†è¢«åˆ†ç±»ä¸ºå…¶ä»–ç±»æˆ–æœªæ£€å‡º)
        fn = matrix[:, i].sum() - tp
        # è®¡ç®—æ£€å‡ºç‡å’Œæ¼æ£€ç‡
        total_gt = tp + fn  # è¯¥ç±»åˆ«çš„çœŸå®ç›®æ ‡æ€»æ•°
        dr = tp / total_gt if total_gt > 0 else 0.0  # æ£€å‡ºç‡ = TP / (TP + FN)
        fnr = fn / total_gt if total_gt > 0 else 0.0  # æ¼æ£€ç‡ = FN / (TP + FN)

        tp_per_class.append(tp)
        fn_per_class.append(fn)
        dr_per_class.append(dr)
        fnr_per_class.append(fnr)

    # è®¡ç®—æ€»ä½“æŒ‡æ ‡
    total_tp = sum(tp_per_class)
    total_fn = sum(fn_per_class)
    total_gt = total_tp + total_fn
    overall_dr = total_tp / total_gt if total_gt > 0 else 0.0  # æ€»ä½“æ£€å‡ºç‡
    overall_fnr = total_fn / total_gt if total_gt > 0 else 0.0  # æ€»ä½“æ¼æ£€ç‡

    # å‡†å¤‡ç»“æœ
    results = {
        'overall_detection_rate': overall_dr,
        'overall_miss_rate': overall_fnr,
        'total_tp': total_tp,
        'total_fn': total_fn,
        'total_ground_truth': total_gt,
        'class_detection_rates': {},
        'class_miss_rates': {},
        'class_details': {}
    }

    # æ·»åŠ å„ç±»åˆ«è¯¦ç»†ä¿¡æ¯
    for i in range(nc):
        class_name = class_names[i] if class_names and i < len(class_names) else f'class_{i}'
        results['class_detection_rates'][class_name] = dr_per_class[i]
        results['class_miss_rates'][class_name] = fnr_per_class[i]
        results['class_details'][class_name] = {
            'tp': tp_per_class[i],
            'fn': fn_per_class[i],
            'ground_truth': tp_per_class[i] + fn_per_class[i],
            'detection_rate': dr_per_class[i],
            'miss_rate': fnr_per_class[i]
        }

    return results


def print_detection_metrics_report(detection_results):
    """
    æ‰“å°æ£€å‡ºç‡å’Œæ¼æ£€ç‡ç»¼åˆæŠ¥å‘Š

    Args:
        detection_results: calculate_detection_metricså‡½æ•°çš„è¿”å›ç»“æœ
    """
    if detection_results is None:
        print("No detection metrics data available")
        return

    print("\n" + "=" * 70)
    print("æ£€å‡ºç‡ä¸æ¼æ£€ç‡åˆ†ææŠ¥å‘Š (Detection & Miss Rate Analysis Report)")
    print("=" * 70)

    # æ€»ä½“æŒ‡æ ‡
    dr_pct = detection_results['overall_detection_rate'] * 100
    mr_pct = detection_results['overall_miss_rate'] * 100

    print(f"\nğŸ“Š æ€»ä½“æŒ‡æ ‡:")
    print(f"   ğŸ¯ æ€»ä½“æ£€å‡ºç‡: {detection_results['overall_detection_rate']:.4f} ({dr_pct:.2f}%)")
    print(f"   ğŸš¨ æ€»ä½“æ¼æ£€ç‡: {detection_results['overall_miss_rate']:.4f} ({mr_pct:.2f}%)")
    print(f"   ğŸ“ˆ æ€»TP: {detection_results['total_tp']}")
    print(f"   ğŸ“‰ æ€»FN: {detection_results['total_fn']}")
    print(f"   ğŸ“‹ æ€»GT: {detection_results['total_ground_truth']}")

    # å„ç±»åˆ«è¯¦æƒ…
    print(f"\nğŸ“‹ å„ç±»åˆ«è¯¦ç»†æŒ‡æ ‡:")
    print("-" * 70)
    print(f"{'ç±»åˆ«':<12} {'æ£€å‡ºç‡':<10} {'æ¼æ£€ç‡':<10} {'TP':<6} {'FN':<6} {'GTæ€»æ•°':<8}")
    print("-" * 70)

    for class_name, details in detection_results['class_details'].items():
        dr_pct = details['detection_rate'] * 100
        mr_pct = details['miss_rate'] * 100
        print(
            f"{class_name:<12} {dr_pct:<9.2f}% {mr_pct:<9.2f}% {details['tp']:<6} {details['fn']:<6} {details['ground_truth']:<8}")

    print("-" * 70)

    # æ€§èƒ½åˆ†æ
    print(f"\nğŸ’¡ æ€§èƒ½åˆ†æ:")
    overall_dr = detection_results['overall_detection_rate']
    overall_mr = detection_results['overall_miss_rate']

    if overall_dr > 0.9:
        print("   âœ… ä¼˜ç§€: æ£€å‡ºç‡>90%ï¼Œæ¨¡å‹æ£€æµ‹èƒ½åŠ›å¼º")
    elif overall_dr > 0.8:
        print("   âš¡ è‰¯å¥½: æ£€å‡ºç‡80-90%ï¼Œæ€§èƒ½è¾ƒå¥½")
    elif overall_dr > 0.7:
        print("   ğŸ“ˆ ä¸­ç­‰: æ£€å‡ºç‡70-80%ï¼Œæœ‰æ”¹è¿›ç©ºé—´")
    else:
        print("   âš ï¸  è¾ƒå·®: æ£€å‡ºç‡<70%ï¼Œéœ€è¦é‡ç‚¹ä¼˜åŒ–")

    if overall_mr > 0.3:
        print("   ğŸš¨ é«˜æ¼æ£€: æ¼æ£€ç‡>30%ï¼Œä¸¥é‡å½±å“å®ç”¨æ€§")
    elif overall_mr > 0.2:
        print("   âš ï¸  ä¸­ç­‰æ¼æ£€: æ¼æ£€ç‡20-30%ï¼Œéœ€è¦å…³æ³¨")
    elif overall_mr > 0.1:
        print("   ğŸ“Š ä½æ¼æ£€: æ¼æ£€ç‡10-20%ï¼Œå¯æ¥å—èŒƒå›´")
    else:
        print("   ğŸ¯ æä½æ¼æ£€: æ¼æ£€ç‡<10%ï¼Œè¡¨ç°ä¼˜ç§€")

    # æ‰¾å‡ºé—®é¢˜ç±»åˆ«
    worst_dr_class = min(detection_results['class_details'].items(),
                         key=lambda x: x[1]['detection_rate'])
    worst_mr_class = max(detection_results['class_details'].items(),
                         key=lambda x: x[1]['miss_rate'])

    print(f"\nğŸ¯ é‡ç‚¹å…³æ³¨:")
    if worst_dr_class[1]['detection_rate'] < 0.8:
        print(f"   ğŸ“‰ '{worst_dr_class[0]}'ç±»åˆ«æ£€å‡ºç‡æœ€ä½({worst_dr_class[1]['detection_rate'] * 100:.1f}%)")
    if worst_mr_class[1]['miss_rate'] > 0.2:
        print(f"   ğŸ“ˆ '{worst_mr_class[0]}'ç±»åˆ«æ¼æ£€ç‡æœ€é«˜({worst_mr_class[1]['miss_rate'] * 100:.1f}%)")

    # æ”¹è¿›å»ºè®®
    print(f"\nğŸ”§ æ”¹è¿›å»ºè®®:")
    if overall_dr < 0.8 or overall_mr > 0.2:
        print("   - é™ä½ç½®ä¿¡åº¦é˜ˆå€¼ä»¥æé«˜æ£€å‡ºç‡")
        print("   - å¢åŠ å›°éš¾æ ·æœ¬å’Œè¾¹ç•Œæ¡ˆä¾‹çš„è®­ç»ƒæ•°æ®")
        print("   - æ£€æŸ¥æ•°æ®æ ‡æ³¨è´¨é‡å’Œä¸€è‡´æ€§")
        print("   - è€ƒè™‘è°ƒæ•´ç½‘ç»œç»“æ„æˆ–æŸå¤±å‡½æ•°")
        print("   - è¿›è¡Œæ•°æ®å¢å¼ºä»¥æé«˜æ¨¡å‹é²æ£’æ€§")
    else:
        print("   âœ… æ¨¡å‹æ£€å‡ºæ€§èƒ½å·²è¾¾åˆ°è‰¯å¥½æ°´å¹³")


def predict():
    # Load a model
    # model = YOLO('yolov8n.pt')  # åŠ è½½å®˜æ–¹çš„æ¨¡å‹æƒé‡ä½œè¯„ä¼°
    model = YOLO("/home/youtian/Documents/pro/pyCode/Dedark-YOLO/runs/detect/DedarkDet/weights/best.pt")  # åŠ è½½è‡ªå®šä¹‰çš„æ¨¡å‹æƒé‡ä½œè¯„ä¼°

    # å®šä¹‰ä½ çš„ç±»åˆ«åç§°
    class_names = ['person', 'debrisflow', 'rockfall']

    # è¿›è¡Œæ¨¡å‹éªŒè¯
    # metrics = model.val()  # ä¸éœ€è¦ä¼ å‚ï¼Œè¿™é‡Œå®šä¹‰çš„æ¨¡å‹ä¼šè‡ªåŠ¨åœ¨è®­ç»ƒçš„æ•°æ®é›†ä¸Šä½œè¯„ä¼°
    metrics = model.val(data="/home/youtian/Documents/pro/pyCode/Dedark-YOLO/ultralytics/cfg/datasets/tielu.yaml")
    # åœ¨ä¸€ä¸ªæ–°çš„æ•°æ®é›†ä¸Šåšè¯„ä¼°ï¼Œä¼ ç»å¯¹è·¯å¾„

    # åŸæœ‰çš„æŒ‡æ ‡
    print("=" * 50)
    print("ä¼ ç»Ÿæ£€æµ‹æŒ‡æ ‡:")
    print("=" * 50)
    print(f"mAP50-95: {metrics.box.map:.4f}")  # map50-95
    print(f"mAP50: {metrics.box.map50:.4f}")  # map50

    print(f"AP75 per class: person-{metrics.box.map75[0]:.4f},"
          f" debrisflow-{metrics.box.map75[1]:.4f},"
          f" rockfall-{metrics.box.map75[2]:.4f}"
          f" mAP75:{sum(metrics.box.map75) / len(metrics.box.map75)}")  # map75

    print(f"F1 scores: person-{metrics.box.f1s[0]:.4f},"
          f" debrisflow-{metrics.box.f1s[1]:.4f},"
          f" rockfall-{metrics.box.f1s[2]:.4f}")  # f1 score

    print(f"mf1: {metrics.box.mf1:.4f}")

    # æ–°å¢çš„æ£€å‡ºç‡å’Œæ¼æ£€ç‡åˆ†æ
    detection_results = calculate_detection_metrics(metrics, class_names)
    print_detection_metrics_report(detection_results)

    return metrics, detection_results


if __name__ == "__main__":
    # train_lowght()
    # test_img()

#############---predict---##############

    # ä½¿ç”¨åŸæœ‰çš„predictå‡½æ•°ï¼ˆåŒ…å«æ£€å‡ºç‡å’Œæ¼æ£€ç‡ï¼‰
    # predict()

    # æˆ–è€…ä½¿ç”¨å¸¦æœ‰è¯¦ç»†åˆ†æçš„ç‰ˆæœ¬
    # predict_with_detailed_analysis()

    # onnx()

#############---testâ€”folder---##############
    try:
        # åŸºç¡€ä½¿ç”¨
        stats = test_folders(
            model_path="/home/youtian/Documents/pro/pyCode/Dedark-YOLO/runs/detect/DedarkDet/weights/best.pt",
            srcpath="/home/youtian/Documents/pro/pyCode/Dedark-YOLO/exp/test",
            confidence_threshold=0.3,
            save_txt=True,
            save_json=True
        )

    except Exception as e:
        print(f"é”™è¯¯: {e}")