import shutil
import sys
import os
import torch
from pathlib import Path
from typing import Union
import cv2
import netron
import time
import numpy as np
from ultralytics import YOLO

os.environ["WANDB_MODE"] = "offline"  # ç¦»çº¿æ¨¡å¼


def train():
    # Load a model
    model = YOLO('yolov8n.yaml')
    # model = RTDETR('rtdetr-l.yaml')
    # print(model)
    # model = YOLO('yolov8m.pt')

    # åšé¢„è®­ç»ƒ
    # model = YOLO('yolov8x.pt')
    # model = YOLO('yolov8n.yaml').load('yolov8n.pt')

    # Train the model
    # model.train(data="HSTS6.yaml", epochs=150, imgsz=640)
    model.train(data="coco128.yaml", epochs=5, imgsz=640)


def train_lowght():
    # Load a model
    model = YOLO('yolov8l.yaml')
    model.train(data="tielu.yaml", epochs=5, imgsz=640)


def onnx(path: Union[str, Path] = "/home/youtian/Documents/pro/pyCode/Dedark-YOLO/epoch20.pt"):
    # you need numpy==1.24.3 ,otherwise it will report Error
    onnxpath = Path(path).with_suffix(".onnx")
    print(onnxpath)
    if not onnxpath.exists():
        model = YOLO(path)
        # Export the model
        model.export(format='onnx')
    try:
        netron.start(str(onnxpath))
    except Exception as e:
        print(e)


def test_img():
    model = YOLO("/home/youtian/Documents/pro/pyCode/Dedark-YOLO/runs/detect/6-1-1833/no-re_loss.pt")
    img = cv2.imread(
        "/home/youtian/Documents/pro/pyCode/datasets/darkpic_test/192.168.39.20_20240727_060304_2246886_2.jpg")
    # img = cv2.imread("/home/youtian/Documents/pro/pyCode/datasets/tielu-yolo/images/test/192.168.39.20_20240727_060304_2246886_2.jpg")
    res = model(img)
    ann = res[0].plot()
    while True:
        cv2.imshow("yolo", ann)
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break
    cur_path = sys.path[0]
    print(cur_path, sys.path)

    cv2.imwrite(cur_path + os.sep + "out2.jpg", ann)


def test_video():
    model = YOLO("/home/youtian/Documents/pro/pyCode/easy_YOLOv8/yolov8x.pt")
    path = Path("/home/youtian/Documents/pro/pyCode/datasets/shitang.mp4")
    cap = cv2.VideoCapture(str(path))

    if not cap.isOpened():
        print("Error: Could not open video.")
        exit()

    size = (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)))

    # ä½¿ç”¨æ­£ç¡®çš„æ–‡ä»¶å
    output_path = Path(f"{path.stem}_output.mp4")
    fourcc = cv2.VideoWriter_fourcc(*'XVID')  # å°è¯•ä½¿ç”¨XVIDç¼–ç 
    out = cv2.VideoWriter(str(output_path), fourcc, 40, size)

    while cap.isOpened():
        ret, frame = cap.read()
        if ret:
            res = model(frame)
            ann = res[0].plot(line_width=3)
            cv2.imshow("yolo", ann)
            out.write(ann)
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break
        else:
            break

    cv2.destroyAllWindows()
    cap.release()
    out.release()


def test_folders(
        model_path: str = "/home/youtian/Documents/pro/pyCode/easy_YOLOv8/runs/detect/YOLOv8l+CHST6+32/weights/best.pt",
        srcpath: str = "/home/youtian/Documents/pro/pyCode/datasets/HSTS6/CHTS6/images/val",
        mothed: str = "YOLO") -> None:
    # åŠ è½½æƒé‡model
    if not isinstance(model_path, Path):
        model_path = Path(model_path)
    # if mothed.lower() == "rtdetr":
    #     model = RTDETR(str(model_path))
    else:
        model = YOLO(model_path)

    src = Path(srcpath) if not isinstance(srcpath, Path) else srcpath
    dst_folder = Path(sys.path[0]) / Path(f"{model_path.parts[-3]}_val_test_pic")
    if dst_folder.exists():
        shutil.rmtree(dst_folder) if any(dst_folder.iterdir()) else dst_folder.rmdir()
    dst_folder.mkdir(exist_ok=True, parents=True)
    timer = 0
    for img_path in src.iterdir():
        start_timer = time.time()
        res = model(cv2.imread(str(img_path)))
        end_timer = time.time()
        timer += end_timer - start_timer

        img = res[0].plot()
        # æŠŠæµ‹è¯•çš„å›¾ç‰‡æå‰resizeæˆç›¸åŒçš„size
        ann = cv2.resize(img, (640, 640))
        cv2.imwrite(str(Path(dst_folder) / Path(img_path.name)), ann)

    # è®¡ç®—æ¯ä¸€å¼ çš„æ¨ç†æ—¶é—´
    print("test time : %f" % (timer / len(list(src.iterdir()))))


def Para4pt(model):
    # ä¸€å®šè¦æ‰¾åˆ°æƒé‡ä¸­çš„modelï¼Œæ‰å¯ä»¥åç»­è¿›è¡Œparameterçš„è®¡ç®—
    # YOLOv8
    # model = model["model"].model
    # YOLOv7
    model = model["model"].model

    total_params = sum(p.numel() for p in model.parameters())
    print(f'{total_params:,} total parameters.')
    # print(f'{total_params / (1024 * 1024):.2f}M total parameters.')


def FLOPs_Para4pt():
    from thop import profile
    """
    æ ¹æ®pytorchçš„ptæ–‡ä»¶æ¥è®¡ç®—æ¨¡å‹çš„FLOPså’Œå‚æ•°é‡ï¼Œuse thop
    Args:
        model:pytorchåŠ è½½å¥½çš„æ¨¡å‹æ–‡ä»¶
    Returns:None
    """

    device = "cuda" if torch.cuda.is_available() else "cpu"
    pa = Path("/home/youtian/Documents/pro/pyCode/ultralytics-YOLOv8/yolov8l.pt")
    model = torch.load(str(pa).strip())

    # å…ˆå°†æ¨¡å‹çš„è°ƒæ•´ä¸ºhalf()æ ¼å¼ï¼Œå†å°†å…¶è´´åˆ°GPU
    model = model.get("model").half().to(device)

    # å‡è®¾æ¨¡å‹æœŸæœ›çš„è¾“å…¥æ˜¯3ä¸ªé€šé“çš„å›¾åƒ
    input_tensor = torch.randn(1, 3, 640, 640)

    # åŒç†ï¼Œå°†æ•°æ®è½¬åŒ–æˆåŠç²¾åº¦ä¹‹åå†åŠ è½½åˆ°GPU
    input_tensor = input_tensor.half().to(device)

    # è°ƒç”¨profileå‡½æ•°è®¡ç®—FLOPså’Œå‚æ•°é‡
    macs, params = profile(model, inputs=(input_tensor,))

    # å°†macsè½¬åŒ–æˆflops
    flops = macs / 1E9 * 2
    params = params / 1E6

    print('flops:{}'.format(flops))
    print('params:{}'.format(params))


def calculate_detection_metrics(metrics, class_names=None):
    """
    è®¡ç®—æ£€å‡ºç‡å’Œæ¼æ£€ç‡æŒ‡æ ‡
    æ£€å‡ºç‡ï¼ˆDetection Rate, DRï¼‰= TP / (TP + FN) = 1 - æ¼æ£€ç‡
    æ¼æ£€ç‡ï¼ˆFalse Negative Rate, FNRï¼‰= FN / (FN + TP) = FN / Total_Ground_Truth

    Args:
        metrics: YOLO validation metrics
        class_names: ç±»åˆ«åç§°åˆ—è¡¨ï¼Œå¦‚ ['person', 'debrisflow', 'rockfall']

    Returns:
        dict: åŒ…å«æ€»ä½“å’Œå„ç±»åˆ«æ£€å‡ºç‡ã€æ¼æ£€ç‡çš„å­—å…¸
    """
    # è·å–æ··æ·†çŸ©é˜µ
    confusion_matrix = metrics.confusion_matrix

    if confusion_matrix is None:
        print("Warning: No confusion matrix available")
        return None

    # è·å–æ··æ·†çŸ©é˜µæ•°æ®
    matrix = confusion_matrix.matrix
    nc = confusion_matrix.nc  # ç±»åˆ«æ•°é‡

    # è®¡ç®—æ¯ä¸ªç±»åˆ«çš„TP, FN, DR, FNR
    tp_per_class = []
    fn_per_class = []
    dr_per_class = []  # Detection Rate
    fnr_per_class = []  # False Negative Rate

    for i in range(nc):
        # TP: å¯¹è§’çº¿å…ƒç´ 
        tp = matrix[i, i]
        # FN: è¯¥ç±»åˆ«åˆ—çš„æ€»å’Œå‡å»TP (çœŸå®æ ‡ç­¾ä¸ºè¯¥ç±»ä½†è¢«åˆ†ç±»ä¸ºå…¶ä»–ç±»æˆ–æœªæ£€å‡º)
        fn = matrix[:, i].sum() - tp
        # è®¡ç®—æ£€å‡ºç‡å’Œæ¼æ£€ç‡
        total_gt = tp + fn  # è¯¥ç±»åˆ«çš„çœŸå®ç›®æ ‡æ€»æ•°
        dr = tp / total_gt if total_gt > 0 else 0.0  # æ£€å‡ºç‡ = TP / (TP + FN)
        fnr = fn / total_gt if total_gt > 0 else 0.0  # æ¼æ£€ç‡ = FN / (TP + FN)

        tp_per_class.append(tp)
        fn_per_class.append(fn)
        dr_per_class.append(dr)
        fnr_per_class.append(fnr)

    # è®¡ç®—æ€»ä½“æŒ‡æ ‡
    total_tp = sum(tp_per_class)
    total_fn = sum(fn_per_class)
    total_gt = total_tp + total_fn
    overall_dr = total_tp / total_gt if total_gt > 0 else 0.0  # æ€»ä½“æ£€å‡ºç‡
    overall_fnr = total_fn / total_gt if total_gt > 0 else 0.0  # æ€»ä½“æ¼æ£€ç‡

    # å‡†å¤‡ç»“æœ
    results = {
        'overall_detection_rate': overall_dr,
        'overall_miss_rate': overall_fnr,
        'total_tp': total_tp,
        'total_fn': total_fn,
        'total_ground_truth': total_gt,
        'class_detection_rates': {},
        'class_miss_rates': {},
        'class_details': {}
    }

    # æ·»åŠ å„ç±»åˆ«è¯¦ç»†ä¿¡æ¯
    for i in range(nc):
        class_name = class_names[i] if class_names and i < len(class_names) else f'class_{i}'
        results['class_detection_rates'][class_name] = dr_per_class[i]
        results['class_miss_rates'][class_name] = fnr_per_class[i]
        results['class_details'][class_name] = {
            'tp': tp_per_class[i],
            'fn': fn_per_class[i],
            'ground_truth': tp_per_class[i] + fn_per_class[i],
            'detection_rate': dr_per_class[i],
            'miss_rate': fnr_per_class[i]
        }

    return results


def print_detection_metrics_report(detection_results):
    """
    æ‰“å°æ£€å‡ºç‡å’Œæ¼æ£€ç‡ç»¼åˆæŠ¥å‘Š

    Args:
        detection_results: calculate_detection_metricså‡½æ•°çš„è¿”å›ç»“æœ
    """
    if detection_results is None:
        print("No detection metrics data available")
        return

    print("\n" + "=" * 70)
    print("æ£€å‡ºç‡ä¸æ¼æ£€ç‡åˆ†ææŠ¥å‘Š (Detection & Miss Rate Analysis Report)")
    print("=" * 70)

    # æ€»ä½“æŒ‡æ ‡
    dr_pct = detection_results['overall_detection_rate'] * 100
    mr_pct = detection_results['overall_miss_rate'] * 100

    print(f"\nğŸ“Š æ€»ä½“æŒ‡æ ‡:")
    print(f"   ğŸ¯ æ€»ä½“æ£€å‡ºç‡: {detection_results['overall_detection_rate']:.4f} ({dr_pct:.2f}%)")
    print(f"   ğŸš¨ æ€»ä½“æ¼æ£€ç‡: {detection_results['overall_miss_rate']:.4f} ({mr_pct:.2f}%)")
    print(f"   ğŸ“ˆ æ€»TP: {detection_results['total_tp']}")
    print(f"   ğŸ“‰ æ€»FN: {detection_results['total_fn']}")
    print(f"   ğŸ“‹ æ€»GT: {detection_results['total_ground_truth']}")

    # å„ç±»åˆ«è¯¦æƒ…
    print(f"\nğŸ“‹ å„ç±»åˆ«è¯¦ç»†æŒ‡æ ‡:")
    print("-" * 70)
    print(f"{'ç±»åˆ«':<12} {'æ£€å‡ºç‡':<10} {'æ¼æ£€ç‡':<10} {'TP':<6} {'FN':<6} {'GTæ€»æ•°':<8}")
    print("-" * 70)

    for class_name, details in detection_results['class_details'].items():
        dr_pct = details['detection_rate'] * 100
        mr_pct = details['miss_rate'] * 100
        print(
            f"{class_name:<12} {dr_pct:<9.2f}% {mr_pct:<9.2f}% {details['tp']:<6} {details['fn']:<6} {details['ground_truth']:<8}")

    print("-" * 70)

    # æ€§èƒ½åˆ†æ
    print(f"\nğŸ’¡ æ€§èƒ½åˆ†æ:")
    overall_dr = detection_results['overall_detection_rate']
    overall_mr = detection_results['overall_miss_rate']

    if overall_dr > 0.9:
        print("   âœ… ä¼˜ç§€: æ£€å‡ºç‡>90%ï¼Œæ¨¡å‹æ£€æµ‹èƒ½åŠ›å¼º")
    elif overall_dr > 0.8:
        print("   âš¡ è‰¯å¥½: æ£€å‡ºç‡80-90%ï¼Œæ€§èƒ½è¾ƒå¥½")
    elif overall_dr > 0.7:
        print("   ğŸ“ˆ ä¸­ç­‰: æ£€å‡ºç‡70-80%ï¼Œæœ‰æ”¹è¿›ç©ºé—´")
    else:
        print("   âš ï¸  è¾ƒå·®: æ£€å‡ºç‡<70%ï¼Œéœ€è¦é‡ç‚¹ä¼˜åŒ–")

    if overall_mr > 0.3:
        print("   ğŸš¨ é«˜æ¼æ£€: æ¼æ£€ç‡>30%ï¼Œä¸¥é‡å½±å“å®ç”¨æ€§")
    elif overall_mr > 0.2:
        print("   âš ï¸  ä¸­ç­‰æ¼æ£€: æ¼æ£€ç‡20-30%ï¼Œéœ€è¦å…³æ³¨")
    elif overall_mr > 0.1:
        print("   ğŸ“Š ä½æ¼æ£€: æ¼æ£€ç‡10-20%ï¼Œå¯æ¥å—èŒƒå›´")
    else:
        print("   ğŸ¯ æä½æ¼æ£€: æ¼æ£€ç‡<10%ï¼Œè¡¨ç°ä¼˜ç§€")

    # æ‰¾å‡ºé—®é¢˜ç±»åˆ«
    worst_dr_class = min(detection_results['class_details'].items(),
                         key=lambda x: x[1]['detection_rate'])
    worst_mr_class = max(detection_results['class_details'].items(),
                         key=lambda x: x[1]['miss_rate'])

    print(f"\nğŸ¯ é‡ç‚¹å…³æ³¨:")
    if worst_dr_class[1]['detection_rate'] < 0.8:
        print(f"   ğŸ“‰ '{worst_dr_class[0]}'ç±»åˆ«æ£€å‡ºç‡æœ€ä½({worst_dr_class[1]['detection_rate'] * 100:.1f}%)")
    if worst_mr_class[1]['miss_rate'] > 0.2:
        print(f"   ğŸ“ˆ '{worst_mr_class[0]}'ç±»åˆ«æ¼æ£€ç‡æœ€é«˜({worst_mr_class[1]['miss_rate'] * 100:.1f}%)")

    # æ”¹è¿›å»ºè®®
    print(f"\nğŸ”§ æ”¹è¿›å»ºè®®:")
    if overall_dr < 0.8 or overall_mr > 0.2:
        print("   - é™ä½ç½®ä¿¡åº¦é˜ˆå€¼ä»¥æé«˜æ£€å‡ºç‡")
        print("   - å¢åŠ å›°éš¾æ ·æœ¬å’Œè¾¹ç•Œæ¡ˆä¾‹çš„è®­ç»ƒæ•°æ®")
        print("   - æ£€æŸ¥æ•°æ®æ ‡æ³¨è´¨é‡å’Œä¸€è‡´æ€§")
        print("   - è€ƒè™‘è°ƒæ•´ç½‘ç»œç»“æ„æˆ–æŸå¤±å‡½æ•°")
        print("   - è¿›è¡Œæ•°æ®å¢å¼ºä»¥æé«˜æ¨¡å‹é²æ£’æ€§")
    else:
        print("   âœ… æ¨¡å‹æ£€å‡ºæ€§èƒ½å·²è¾¾åˆ°è‰¯å¥½æ°´å¹³")


def predict():
    # Load a model
    # model = YOLO('yolov8n.pt')  # åŠ è½½å®˜æ–¹çš„æ¨¡å‹æƒé‡ä½œè¯„ä¼°
    model = YOLO("/home/youtian/Documents/pro/pyCode/Dedark-YOLO/runs/detect/baseline/weights/best.pt")  # åŠ è½½è‡ªå®šä¹‰çš„æ¨¡å‹æƒé‡ä½œè¯„ä¼°

    # å®šä¹‰ä½ çš„ç±»åˆ«åç§°
    class_names = ['person', 'debrisflow', 'rockfall']

    # è¿›è¡Œæ¨¡å‹éªŒè¯
    # metrics = model.val()  # ä¸éœ€è¦ä¼ å‚ï¼Œè¿™é‡Œå®šä¹‰çš„æ¨¡å‹ä¼šè‡ªåŠ¨åœ¨è®­ç»ƒçš„æ•°æ®é›†ä¸Šä½œè¯„ä¼°
    metrics = model.val(data="/home/youtian/Documents/pro/pyCode/Dedark-YOLO/ultralytics/cfg/datasets/tielu.yaml")
    # åœ¨ä¸€ä¸ªæ–°çš„æ•°æ®é›†ä¸Šåšè¯„ä¼°ï¼Œä¼ ç»å¯¹è·¯å¾„

    # åŸæœ‰çš„æŒ‡æ ‡
    print("=" * 50)
    print("ä¼ ç»Ÿæ£€æµ‹æŒ‡æ ‡:")
    print("=" * 50)
    print(f"mAP50-95: {metrics.box.map:.4f}")  # map50-95
    print(f"mAP50: {metrics.box.map50:.4f}")  # map50
    print(f"mAP75: {metrics.box.map75:.4f}")  # map75
    print(f"F1 scores: {metrics.box.f1s}")  # f1 score
    print(f"mAPs per class: {metrics.box.maps}")  # åŒ…å«æ¯ä¸ªç±»åˆ«çš„map50-95åˆ—è¡¨

    # æ–°å¢çš„æ£€å‡ºç‡å’Œæ¼æ£€ç‡åˆ†æ
    detection_results = calculate_detection_metrics(metrics, class_names)
    print_detection_metrics_report(detection_results)

    return metrics, detection_results


def predict_with_detailed_analysis():
    """
    å¸¦æœ‰è¯¦ç»†åˆ†æçš„é¢„æµ‹å‡½æ•°ï¼ŒåŒ…æ‹¬æ¼æ£€ç‡å’Œå…¶ä»–æŒ‡æ ‡çš„ç»¼åˆåˆ†æ
    """
    # Load a model
    model = YOLO("/home/youtian/Documents/pro/pyCode/Dedark-YOLO/runs/detect/baseline/weights/best.pt")

    # å®šä¹‰ä½ çš„ç±»åˆ«åç§°
    class_names = ['person', 'debrisflow', 'rockfall']

    # è¿›è¡Œæ¨¡å‹éªŒè¯
    metrics = model.val(data="/home/youtian/Documents/pro/pyCode/Dedark-YOLO/ultralytics/cfg/datasets/tielu.yaml")

    # è®¡ç®—æ£€å‡ºç‡å’Œæ¼æ£€ç‡
    detection_results = calculate_detection_metrics(metrics, class_names)

    # ç»¼åˆæŠ¥å‘Š
    print("\n" + "=" * 70)
    print("æ¨¡å‹æ€§èƒ½ç»¼åˆåˆ†ææŠ¥å‘Š")
    print("=" * 70)

    # åŸºç¡€æŒ‡æ ‡
    print(f"\nğŸ¯ æ£€æµ‹ç²¾åº¦æŒ‡æ ‡:")
    print(f"   mAP@0.5:0.95: {metrics.box.map:.4f}")
    print(f"   mAP@0.5:     {metrics.box.map50:.4f}")
    print(f"   mAP@0.75:    {metrics.box.map75:.4f}")
    print(f"   å¹³å‡ç²¾ç¡®ç‡:   {metrics.box.mp:.4f}")
    print(f"   å¹³å‡å¬å›ç‡:   {metrics.box.mr:.4f}")

    # æ£€å‡ºç‡å’Œæ¼æ£€ç‡æŒ‡æ ‡
    if detection_results:
        print(f"\nğŸ¯ æ£€å‡ºç‡æŒ‡æ ‡:")
        print(
            f"   æ€»ä½“æ£€å‡ºç‡: {detection_results['overall_detection_rate']:.4f} ({detection_results['overall_detection_rate'] * 100:.2f}%)")
        print(f"\nğŸš¨ æ¼æ£€ç‡æŒ‡æ ‡:")
        print(
            f"   æ€»ä½“æ¼æ£€ç‡: {detection_results['overall_miss_rate']:.4f} ({detection_results['overall_miss_rate'] * 100:.2f}%)")

        # å„ç±»åˆ«å¯¹æ¯”
        print(f"\nğŸ“Š å„ç±»åˆ«æ€§èƒ½å¯¹æ¯”:")
        print(f"{'ç±»åˆ«':<12} {'mAP@0.5':<10} {'å¬å›ç‡':<10} {'æ£€å‡ºç‡':<10} {'æ¼æ£€ç‡':<10} {'F1':<10}")
        print("-" * 70)

        for i, class_name in enumerate(class_names):
            if i < len(metrics.box.maps):
                map50 = metrics.box.ap50[i] if hasattr(metrics.box, 'ap50') and i < len(metrics.box.ap50) else 0
                recall = metrics.box.r[i] if hasattr(metrics.box, 'r') and i < len(metrics.box.r) else 0
                detection_rate = detection_results['class_detection_rates'].get(class_name, 0)
                miss_rate = detection_results['class_miss_rates'].get(class_name, 0)
                f1 = metrics.box.f1[i] if hasattr(metrics.box, 'f1') and i < len(metrics.box.f1) else 0

                print(
                    f"{class_name:<12} {map50:<10.3f} {recall:<10.3f} {detection_rate * 100:<9.1f}% {miss_rate * 100:<9.1f}% {f1:<10.3f}")

    # æ€§èƒ½è¯„ä¼°
    print(f"\nğŸ’¡ æ¨¡å‹è¯„ä¼°:")
    overall_map = metrics.box.map
    overall_detection_rate = detection_results['overall_detection_rate'] if detection_results else 0
    overall_miss_rate = detection_results['overall_miss_rate'] if detection_results else 0

    if overall_map > 0.7 and overall_detection_rate > 0.9:
        print("   âœ… ä¼˜ç§€: é«˜ç²¾åº¦é«˜æ£€å‡ºç‡ï¼Œæ¨¡å‹æ€§èƒ½ä¼˜ç§€")
    elif overall_map > 0.5 and overall_detection_rate > 0.8:
        print("   âš¡ è‰¯å¥½: ç²¾åº¦å’Œæ£€å‡ºç‡éƒ½åœ¨è‰¯å¥½èŒƒå›´")
    elif overall_miss_rate > 0.3:
        print("   âš ï¸  æ³¨æ„: æ¼æ£€ç‡è¾ƒé«˜ï¼Œå¯èƒ½å½±å“å®é™…åº”ç”¨")
    else:
        print("   ğŸ“ˆ éœ€æ”¹è¿›: å»ºè®®è¿›ä¸€æ­¥ä¼˜åŒ–æ¨¡å‹")

    return metrics, detection_results


if __name__ == "__main__":
    # train_lowght()
    # test_img()

    # ä½¿ç”¨åŸæœ‰çš„predictå‡½æ•°ï¼ˆåŒ…å«æ£€å‡ºç‡å’Œæ¼æ£€ç‡ï¼‰
    predict()

    # æˆ–è€…ä½¿ç”¨å¸¦æœ‰è¯¦ç»†åˆ†æçš„ç‰ˆæœ¬
    # predict_with_detailed_analysis()

    # onnx()